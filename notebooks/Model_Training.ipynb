{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Customer Feedback Sentiment Predictor\n",
    "This project aims to build a sentiment analysis model using the Amazon Reviews Dataset. The objective is to predict customer sentiment based on review text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n",
      "********************************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568428 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n",
      "None\n",
      "********************************************************************************\n",
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertModel,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Reviews.csv')\n",
    "\n",
    "print(df.shape)\n",
    "print(80*'*')\n",
    "print(df.info())\n",
    "print(80*'*')\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data, we can proceed with the next steps for building the **Interactive Customer Feedback Sentiment Predictor**.\n",
    "\n",
    "### Let's start with **Step 1: Data Preprocessing**.\n",
    "\n",
    "1. **Data Cleaning and Dropping Unnecessary Columns**:\n",
    "   We'll drop irrelevant columns like `Id`, `ProductId`, `UserId`, `ProfileName`, `HelpfulnessNumerator`, `HelpfulnessDenominator`, `Time`, and `Summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score    0\n",
      "Text     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant columns\n",
    "df_cleaned = df.drop(['Id', 'ProductId', 'UserId', 'ProfileName', \n",
    "                      'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'], axis=1)\n",
    "\n",
    "# Check for missing values\n",
    "print(df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! There are no missing values in the `Score` and `Text` columns, so we can proceed with the next step.\n",
    "\n",
    "### Step 2: Text Preprocessing for NLP\n",
    "\n",
    "Weâ€™ll clean the text data by:\n",
    "- Lowercasing the text.\n",
    "- Removing punctuation, special characters, and numbers.\n",
    "- Removing stopwords (commonly used words like \"the\", \"is\", etc., that don't add much meaning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  bought several vitality canned dog food produc...  \n",
       "1  product arrived labeled jumbo salted peanutsth...  \n",
       "2  confection around centuries light pillowy citr...  \n",
       "3  looking secret ingredient robitussin believe f...  \n",
       "4  great taffy great price wide assortment yummy ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function for cleaning the text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation, numbers, and special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join the words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to the 'Text' column\n",
    "df_cleaned['cleaned_text'] = df_cleaned['Text'].apply(preprocess_text)\n",
    "\n",
    "# Preview the cleaned data\n",
    "df_cleaned[['Text', 'cleaned_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step: Sentiment Labeling\n",
    "We'll create a `Sentiment` column based on the `Score`:\n",
    "- Scores 4 and 5 â†’ Positive sentiment\n",
    "- Scores 1 and 2 â†’ Negative sentiment\n",
    "- Score 3 â†’ Neutral sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text Sentiment\n",
       "0  bought several vitality canned dog food produc...  Positive\n",
       "1  product arrived labeled jumbo salted peanutsth...  Negative\n",
       "2  confection around centuries light pillowy citr...  Positive\n",
       "3  looking secret ingredient robitussin believe f...  Negative\n",
       "4  great taffy great price wide assortment yummy ...  Positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_sentiment(score):\n",
    "    if score in [4, 5]:\n",
    "        return 'Positive'\n",
    "    elif score in [1, 2]:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment labeling\n",
    "df_cleaned['Sentiment'] = df_cleaned['Score'].apply(label_sentiment)\n",
    "\n",
    "# Preview the updated dataset\n",
    "df_cleaned[['cleaned_text', 'Sentiment']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Splitting the Dataset:**\n",
    "We'll split the dataset into training and testing sets to train and evaluate our sentiment prediction model.\n",
    "\n",
    "\n",
    "### 2. **Text Vectorization:**\n",
    "Weâ€™ll convert the text into a format that the model can work with, such as using a **TF-IDF vectorizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 454763\n",
      "Testing set size: 113691\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X = df_cleaned['cleaned_text']  \n",
    "y = df_cleaned['Sentiment']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TF-IDF matrix shape: (454763, 5000)\n",
      "Testing TF-IDF matrix shape: (113691, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limiting to top 5000 features for performance\n",
    "\n",
    "# Fit and transform the training data, transform the test data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"Training TF-IDF matrix shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing TF-IDF matrix shape: {X_test_tfidf.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Model Training:**\n",
    "Letâ€™s train a simple classifier like **Logistic Regression** to predict the sentiment based on the TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 86.69%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.67      0.70     16181\n",
      "     Neutral       0.51      0.19      0.27      8485\n",
      "    Positive       0.90      0.97      0.93     89025\n",
      "\n",
      "    accuracy                           0.87    113691\n",
      "   macro avg       0.71      0.61      0.64    113691\n",
      "weighted avg       0.85      0.87      0.85    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model on the TF-IDF vectors and labels\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **model accuracy** of ***86.69%*** is a decent starting point, but there is room for improvement, especially in distinguishing between the **Neutral** and **Negative** classes.\n",
    "\n",
    "The **classification report** reveals the following:\n",
    "\n",
    "- **Positive reviews** are predicted with strong performance, achieving a high precision of 0.90 and recall of 0.97, which shows the model is highly effective at identifying positive sentiment.\n",
    "- **Negative reviews** are reasonably well predicted, with a precision of 0.73 and recall of 0.67, though these values suggest some room for improvement.\n",
    "- **Neutral reviews**, however, show the weakest performance, with a precision of 0.51 and a recall of just 0.19, indicating that the model struggles to accurately classify neutral reviews.\n",
    "\n",
    "\n",
    "The model has difficulty distinguishing between **Neutral** and **Negative** reviews, which is likely due to class imbalance or other challenges in the data, such as noise or insufficient features for proper classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 86.69%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.67      0.70     16181\n",
      "     Neutral       0.51      0.19      0.27      8485\n",
      "    Positive       0.90      0.97      0.93     89025\n",
      "\n",
      "    accuracy                           0.87    113691\n",
      "   macro avg       0.71      0.61      0.64    113691\n",
      "weighted avg       0.85      0.87      0.85    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try to Increase the iterations\n",
    "model = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "# Train the model on the TF-IDF vectors and labels\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 86.70%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.67      0.70     16181\n",
      "     Neutral       0.51      0.19      0.27      8485\n",
      "    Positive       0.90      0.97      0.93     89025\n",
      "\n",
      "    accuracy                           0.87    113691\n",
      "   macro avg       0.72      0.61      0.64    113691\n",
      "weighted avg       0.85      0.87      0.85    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try a different solver\n",
    "model = LogisticRegression(solver='saga', n_jobs=-1)\n",
    "\n",
    "# Train the model on the TF-IDF vectors and labels\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 86.68%\n",
      "Classification Report for Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.68      0.70     16181\n",
      "     Neutral       0.49      0.21      0.30      8485\n",
      "    Positive       0.90      0.96      0.93     89025\n",
      "\n",
      "    accuracy                           0.87    113691\n",
      "   macro avg       0.71      0.62      0.64    113691\n",
      "weighted avg       0.85      0.87      0.85    113691\n",
      "\n",
      "Time taken by Logistic Regression: 109.33 seconds\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 89.45%\n",
      "Classification Report for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.61      0.73     16181\n",
      "     Neutral       0.98      0.39      0.56      8485\n",
      "    Positive       0.89      0.99      0.94     89025\n",
      "\n",
      "    accuracy                           0.89    113691\n",
      "   macro avg       0.93      0.66      0.74    113691\n",
      "weighted avg       0.90      0.89      0.88    113691\n",
      "\n",
      "Time taken by Random Forest: 3568.92 seconds\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:43:23] WARNING: D:\\bld\\xgboost-split_1727635034975\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 80.38%\n",
      "Classification Report for XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.15      0.26     16181\n",
      "     Neutral       0.71      0.01      0.03      8485\n",
      "    Positive       0.80      1.00      0.89     89025\n",
      "\n",
      "    accuracy                           0.80    113691\n",
      "   macro avg       0.79      0.39      0.39    113691\n",
      "weighted avg       0.80      0.80      0.73    113691\n",
      "\n",
      "Time taken by XGBoost: 138.30 seconds\n",
      "\n",
      "Training SVM...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params:\n\u001b[0;32m     37\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_tfidf, y_train_encoded)\n\u001b[0;32m     39\u001b[0m     model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define models with improved parameters\n",
    "models = {\n",
    "    \"Random Forest\": (RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, class_weight='balanced', n_jobs=-1), {}),  # Adjusted parameters\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, (model, params) in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    if params:\n",
    "        grid_search = GridSearchCV(model, params, cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train_tfidf, y_train_encoded)\n",
    "        model = grid_search.best_estimator_\n",
    "    else:\n",
    "        model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Decode predictions back to original labels\n",
    "    y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_decoded)\n",
    "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Classification Report for {model_name}:\\n\", classification_report(y_test, y_pred_decoded))\n",
    "    print(f\"Time taken by {model_name}: {time.time() - start_time:.2f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- Accuracy: **86.68%** is a solid baseline, though there's room for improvement, particularly in distinguishing between **Neutral** and **Negative** reviews.\n",
    "- The **classification report** reveals:\n",
    "  - **Positive reviews** are predicted with high precision (0.90) and recall (0.96), indicating strong performance in identifying positive sentiment.\n",
    "  - **Negative reviews** show decent performance with precision (0.73) and recall (0.68), though there's still some room for improvement.\n",
    "  - **Neutral reviews** have notably lower performance, with precision (0.49) and recall (0.21), suggesting the model struggles to properly classify neutral reviews.\n",
    "\n",
    "This indicates that while the model performs well on Positive reviews, it faces difficulties with **Neutral** and **Negative** reviews, likely due to class imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "### Random Forest\n",
    "- Accuracy: **89.45%**, showing an improvement over Logistic Regression.\n",
    "- The **classification report** shows:\n",
    "  - **Positive reviews** are predicted well with precision (0.89) and recall (0.99), indicating excellent performance.\n",
    "  - **Negative reviews** show decent performance with precision (0.92) and recall (0.61), though recall could be further improved.\n",
    "  - **Neutral reviews** are still challenging, with precision (0.98) but a low recall (0.39), indicating the model tends to over-predict Neutral reviews, but misses many actual Neutral cases.\n",
    "\n",
    "The Random Forest model shows better overall performance than Logistic Regression, but still faces challenges with Neutral reviews, likely due to class imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "### XGBoost\n",
    "- Accuracy: **80.38%**, lower than both Logistic Regression and Random Forest.\n",
    "- The **classification report** reveals:\n",
    "  - **Positive reviews** are predicted with high precision (0.80) and recall (1.00), but performance on Negative and Neutral reviews is poor.\n",
    "  - **Negative reviews** have poor recall (0.15) and precision (0.87), indicating significant difficulty in distinguishing them from other classes.\n",
    "  - **Neutral reviews** show extremely poor recall (0.01), suggesting the model is almost unable to identify Neutral reviews at all.\n",
    "\n",
    "The XGBoost model has the lowest performance, particularly on **Neutral** reviews, highlighting the challenges of dealing with class imbalance and noisy features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.8947937831490619\n",
      "Classification Report for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.61      0.74     16181\n",
      "     Neutral       0.97      0.39      0.56      8485\n",
      "    Positive       0.89      0.99      0.94     89025\n",
      "\n",
      "    accuracy                           0.89    113691\n",
      "   macro avg       0.93      0.66      0.74    113691\n",
      "weighted avg       0.90      0.89      0.88    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the fixed parameters and variations\n",
    "n_estimators = 200\n",
    "class_weight = 'balanced'\n",
    "\n",
    "# Define the hyperparameter values\n",
    "max_depths = [None, 5]        \n",
    "min_samples_splits = [2, 10]  \n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate through combinations of hyperparameters\n",
    "for max_depth in max_depths:\n",
    "    for min_samples_split in min_samples_splits:\n",
    "        print(f\"Training Random Forest with max_depth={max_depth}, min_samples_split={min_samples_split}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create and train the model\n",
    "        rf_model = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                           max_depth=max_depth, \n",
    "                                           min_samples_split=min_samples_split,\n",
    "                                           class_weight=class_weight,\n",
    "                                           n_jobs=-1)\n",
    "        rf_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "        # Decode predictions back to original labels\n",
    "        y_pred_rf_decoded = label_encoder.inverse_transform(y_pred_rf)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy_rf = accuracy_score(y_test, y_pred_rf_decoded)\n",
    "        report = classification_report(y_test, y_pred_rf_decoded)\n",
    "\n",
    "        results.append({\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'accuracy': accuracy_rf,\n",
    "            'report': report\n",
    "        })\n",
    "\n",
    "        print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "        print(report)\n",
    "        print(f\"Time taken: {time.time() - start_time:.2f} seconds\\n\")\n",
    "\n",
    "# Print all results\n",
    "print(\"Results:\")\n",
    "for result in results:\n",
    "    print(f\"Max Depth: {result['max_depth']}, Min Samples Split: {result['min_samples_split']}, \"\n",
    "          f\"Accuracy: {result['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1: Max Depth: None, Min Samples Split: 10, Max Features: sqrt\n",
      "Accuracy: 90.06%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.67      0.76     16181\n",
      "     Neutral       0.94      0.40      0.57      8485\n",
      "    Positive       0.90      0.99      0.94     89025\n",
      "\n",
      "    accuracy                           0.90    113691\n",
      "   macro avg       0.91      0.69      0.76    113691\n",
      "weighted avg       0.90      0.90      0.89    113691\n",
      "\n",
      "Time taken: 2288.56 seconds\n",
      "\n",
      "Combination 2: Max Depth: None, Min Samples Split: 10, Max Features: log2\n",
      "Accuracy: 89.54%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.61      0.74     16181\n",
      "     Neutral       0.98      0.39      0.55      8485\n",
      "    Positive       0.89      1.00      0.94     89025\n",
      "\n",
      "    accuracy                           0.90    113691\n",
      "   macro avg       0.93      0.66      0.74    113691\n",
      "weighted avg       0.90      0.90      0.88    113691\n",
      "\n",
      "Time taken: 1003.38 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter combinations\n",
    "combinations = [\n",
    "    {'max_depth': None, 'min_samples_split': 10, 'max_features': 'sqrt'},\n",
    "    {'max_depth': None, 'min_samples_split': 10, 'max_features': 'log2'}\n",
    "]\n",
    "\n",
    "# Store results and models\n",
    "results = []\n",
    "models = []\n",
    "\n",
    "# Train and evaluate each combination\n",
    "for params in combinations:\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=200, \n",
    "        class_weight='balanced', \n",
    "        n_jobs=-1, \n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    rf_model.fit(X_train_tfidf, y_train_encoded)\n",
    "    y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "    # Decode predictions back to original labels\n",
    "    y_pred_rf_decoded = label_encoder.inverse_transform(y_pred_rf)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf_decoded)\n",
    "    report = classification_report(y_test, y_pred_rf_decoded)\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'accuracy': accuracy_rf,\n",
    "        'report': report,\n",
    "        'time': time.time() - start_time\n",
    "    })\n",
    "    models.append(rf_model)  # Store the trained model\n",
    "\n",
    "# Print results\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Combination {i + 1}: Max Depth: {result['params']['max_depth']}, \"\n",
    "          f\"Min Samples Split: {result['params']['min_samples_split']}, \"\n",
    "          f\"Max Features: {result['params']['max_features']}\")\n",
    "    print(f\"Accuracy: {result['accuracy'] * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", result['report'])\n",
    "    print(f\"Time taken: {result['time']:.2f} seconds\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the best model based on accuracy\n",
    "best_model_index = max(range(len(results)), key=lambda i: results[i]['accuracy'])\n",
    "best_model = models[best_model_index]\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "for i, result in enumerate(results):\n",
    "    if result['params'] == {'max_depth': None, 'min_samples_split': 10, 'max_features': 'sqrt'}:\n",
    "        joblib.dump(models[i], 'rf_model_sqrt.joblib')\n",
    "        print(\"Model saved as 'rf_model_sqrt.joblib'\")\n",
    "\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.joblib')  # Save the vectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (TF-IDF)\n",
    "Using a Random Forest Classifier, we achieved **90.06% accuracy**. While the performance is solid, it does not fully capture the context and nuances of customer feedback, motivating our shift to fine-tuning **DistilBERT**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning DistilBERT:\n",
    "\n",
    "I initially attempted to fine-tune **DistilBERT** for the task to explore how leveraging a state-of-the-art transformer model could improve accuracy.I tried to fine-tune the model; However, due to insufficient GPU resources, the training process was **prohibitively slow**, which preventing full fine-tuning of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DistilBERT embeddings:**\n",
    "\n",
    "To still leverage the power of DistilBERT without fully fine-tuning, I used **DistilBERT embeddings** as feature vectors, and then applied **Random Forest** for classification. This approach resulted in an accuracy of **88%**, slightly lower than the Random Forest model alone, which achieved **90%** accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenizer and Model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Prepare the dataset\n",
    "df_hf = df_cleaned[[\"cleaned_text\", \"Sentiment\"]].rename(columns={\"cleaned_text\": \"text\", \"Sentiment\": \"label\"})\n",
    "df_hf[\"label\"] = df_hf[\"label\"].map({\"negative\": 0, \"neutral\": 1, \"positive\": 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing labels\n",
    "df_hf = df_hf.dropna(subset=[\"label\"])\n",
    "\n",
    "# Check for missing or invalid labels\n",
    "if df_hf[\"label\"].isnull().any():\n",
    "    raise ValueError(\"Labels contain missing values. Please clean your dataset.\")\n",
    "\n",
    "dataset = Dataset.from_pandas(df_hf)\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Rename \"label\" to \"labels\" (required by Hugging Face Trainer)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Debugging: Print a sample to inspect inputs\n",
    "print(\"Sample tokenized data:\", tokenized_datasets[0])\n",
    "\n",
    "# Split into train/test\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# Use Data Collator for Padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Define Trainer arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "trainer.save_model(\"./saved_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DistilBERT embeddings:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2066, 2116, 2500, 2056, 7107, 4157, 6659, 7107, 4157, 2123, 2102,\n",
      "         4965,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Tokenize the training and test data\n",
    "X_train_tokens = [tokenize_text(text) for text in X_train]\n",
    "X_test_tokens = [tokenize_text(text) for text in X_test]\n",
    "\n",
    "# Check one example tokenization output\n",
    "print(X_train_tokens[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251349    0\n",
      "523262    2\n",
      "224543    2\n",
      "291632    2\n",
      "37385     2\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Label encoding for sentiments\n",
    "sentiment_mapping = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "y_train_encoded = y_train.map(sentiment_mapping)\n",
    "y_test_encoded = y_test.map(sentiment_mapping)\n",
    "\n",
    "# Verify the mapping\n",
    "print(y_train_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized inputs into PyTorch tensors\n",
    "def create_dataset(tokens, labels):\n",
    "    input_ids = torch.cat([token['input_ids'] for token in tokens], dim=0)\n",
    "    attention_masks = torch.cat([token['attention_mask'] for token in tokens], dim=0)\n",
    "    labels = torch.tensor(labels.values)\n",
    "    \n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    return dataset\n",
    "\n",
    "# Create the DataLoader objects for training and testing\n",
    "train_dataset = create_dataset(X_train_tokens, y_train_encoded)\n",
    "test_dataset = create_dataset(X_test_tokens, y_test_encoded)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0/28423: Loss = 1.0795\n",
      "Epoch 1, Batch 100/28423: Loss = 1.0977\n",
      "Epoch 1, Batch 200/28423: Loss = 0.6802\n",
      "Epoch 1, Batch 300/28423: Loss = 0.8028\n",
      "Epoch 1, Batch 400/28423: Loss = 0.8547\n",
      "Epoch 1, Batch 500/28423: Loss = 0.8346\n",
      "Epoch 1, Batch 600/28423: Loss = 0.8413\n",
      "Epoch 1, Batch 700/28423: Loss = 0.7786\n",
      "Epoch 1, Batch 800/28423: Loss = 0.6608\n",
      "Epoch 1, Batch 900/28423: Loss = 0.7753\n",
      "Epoch 1, Batch 1000/28423: Loss = 0.7750\n",
      "Epoch 1, Batch 1100/28423: Loss = 0.8219\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "accumulation_steps = 4  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_preds += (preds == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 0:  \n",
    "            print(f\"Epoch {epoch+1}, Batch {i}/{len(train_loader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "correct_preds = 0\n",
    "total_preds = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_preds += (preds == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = correct_preds / total_preds * 100\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56846/56846 [4:51:09<00:00,  3.25it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for testing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14212/14212 [1:17:44<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load DistilBERT model and tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Function to extract embeddings in a memory-efficient way\n",
    "def extract_embeddings_memory_efficient(texts, tokenizer, model, batch_size=8, save_path=\"train_embeddings_chunk\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            encoded = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "            input_ids = encoded['input_ids']\n",
    "            attention_mask = encoded['attention_mask']\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()  # CLS token\n",
    "\n",
    "            # Append each batch to a file\n",
    "            with open(f\"{save_path}_{i // batch_size}.npy\", \"wb\") as f:\n",
    "                np.save(f, batch_embeddings)\n",
    "\n",
    "# Combine saved chunks into a single array\n",
    "def combine_embedding_chunks(save_path, total_chunks):\n",
    "    embeddings = []\n",
    "    for chunk_idx in range(total_chunks):\n",
    "        chunk_path = f\"{save_path}_{chunk_idx}.npy\"\n",
    "        with open(chunk_path, \"rb\") as f:\n",
    "            chunk_data = np.load(f)\n",
    "            embeddings.append(chunk_data)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Generate embeddings for training data\n",
    "if os.path.exists(\"train_embeddings_combined.npy\"):\n",
    "    X_train_embeddings = np.load(\"train_embeddings_combined.npy\")\n",
    "else:\n",
    "    print(\"Generating embeddings for training data...\")\n",
    "    extract_embeddings_memory_efficient(X_train.tolist(), tokenizer, distilbert, batch_size=8, save_path=\"train_embeddings_chunk\")\n",
    "    X_train_embeddings = combine_embedding_chunks(\"train_embeddings_chunk\", len(X_train) // 8)\n",
    "    np.save(\"train_embeddings_combined.npy\", X_train_embeddings)\n",
    "\n",
    "# Generate embeddings for testing data\n",
    "if os.path.exists(\"test_embeddings_combined.npy\"):\n",
    "    X_test_embeddings = np.load(\"test_embeddings_combined.npy\")\n",
    "else:\n",
    "    print(\"Generating embeddings for testing data...\")\n",
    "    extract_embeddings_memory_efficient(X_test.tolist(), tokenizer, distilbert, batch_size=8, save_path=\"test_embeddings_chunk\")\n",
    "    X_test_embeddings = combine_embedding_chunks(\"test_embeddings_chunk\", len(X_test) // 8)\n",
    "    np.save(\"test_embeddings_combined.npy\", X_test_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronized sizes: X_train_embeddings: 454760, y_train: 454760\n",
      "Training with parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 10, 'max_features': 'sqrt', 'class_weight': 'balanced'}\n",
      "Combination 1: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 10, 'max_features': 'sqrt', 'class_weight': 'balanced'}\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.49      0.64     16181\n",
      "     Neutral       0.99      0.38      0.55      8485\n",
      "    Positive       0.87      1.00      0.93     89022\n",
      "\n",
      "    accuracy                           0.88    113688\n",
      "   macro avg       0.93      0.62      0.71    113688\n",
      "weighted avg       0.89      0.88      0.86    113688\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Synchronize the size of y_train with X_train_embeddings\n",
    "if len(X_train_embeddings) < len(y_train):\n",
    "    y_train = y_train[:len(X_train_embeddings)]\n",
    "\n",
    "\n",
    "if len(X_test_embeddings) < len(y_test):\n",
    "    y_test = y_test[:len(X_test_embeddings)]\n",
    "\n",
    "# Verify the sizes are now aligned\n",
    "print(f\"Synchronized sizes: X_train_embeddings: {len(X_train_embeddings)}, y_train: {len(y_train)}\")\n",
    "\n",
    "# Define hyperparameter combinations\n",
    "combinations = [\n",
    "    {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 10, 'max_features': 'sqrt', 'class_weight': 'balanced'}\n",
    "    ]\n",
    "\n",
    "# Store results for each combination\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each combination\n",
    "for params in combinations:\n",
    "    rf = RandomForestClassifier(\n",
    "        random_state=42, \n",
    "        **params\n",
    "    )\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "    rf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = rf.predict(X_test_embeddings)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report\n",
    "    })\n",
    "\n",
    "# Print results\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Combination {i + 1}: {result['params']}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(result['report'])\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
